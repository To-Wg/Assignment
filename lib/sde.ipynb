{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIIuuJ16HT57",
        "outputId": "fc4d804d-d325-4c04-b9bc-19b50986c2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.4.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch-lightning\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch-lightning-2.0.2 torchmetrics-0.11.4 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Ge_P0MJMHbuk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Fre65QueLEMH"
      },
      "outputs": [],
      "source": [
        "class VariancePreservingSDE(pl.LightningModule):\n",
        "    def __init__(self, beta_min=0.1, beta_max=20.0, T=1.0, t_epsilon=0.001):\n",
        "        super().__init__()\n",
        "        self.beta_min = beta_min\n",
        "        self.beta_max = beta_max\n",
        "        self.T = T\n",
        "        self.t_epsilon = t_epsilon\n",
        "  \n",
        "    def beta(self, t):\n",
        "        return self.beta_min + (self.beta_max-self.beta_min)*t\n",
        "\n",
        "    def mean_weight(self, t):\n",
        "        return torch.exp(-0.25 * t**2 * (self.beta_max-self.beta_min) - 0.5 * t * self.beta_min)\n",
        "\n",
        "    def var(self, t):\n",
        "        return 1. - torch.exp(-0.5 * t**2 * (self.beta_max-self.beta_min) - t * self.beta_min)\n",
        "\n",
        "    def f(self, t, y):\n",
        "        return - 0.5 * self.beta(t) * y\n",
        "\n",
        "    def g(self, t, y):\n",
        "        beta_t = self.beta(t)\n",
        "        return torch.ones_like(y) * beta_t**0.5\n",
        "\n",
        "    def sample(self, t, y0, return_noise=False):\n",
        "        \"\"\"\n",
        "        sample yt | y0\n",
        "        if return_noise=True, also return std and g for reweighting the denoising score matching loss\n",
        "        \"\"\"\n",
        "        mu = self.mean_weight(t) * y0\n",
        "        std = self.var(t) ** 0.5\n",
        "        epsilon = torch.randn_like(y0)\n",
        "        yt = epsilon * std + mu\n",
        "        if not return_noise:\n",
        "            return yt\n",
        "        else:\n",
        "            return yt, epsilon, std, self.g(t, yt)\n",
        "\n",
        "    def sample_debiasing_t(self, shape):\n",
        "        \"\"\"\n",
        "        non-uniform sampling of t to debias the weight std^2/g^2\n",
        "        the sampling distribution is proportional to g^2/std^2 for t >= t_epsilon\n",
        "        for t < t_epsilon, it's truncated\n",
        "        \"\"\"\n",
        "        return sample_vp_truncated_q(shape, self.beta_min, self.beta_max, t_epsilon=self.t_epsilon, T=self.T)\n",
        "    \n",
        "\n",
        "class PluginReverseSDE(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    inverting a given base sde with drift `f` and diffusion `g`, and an inference sde's drift `a` by\n",
        "    f <- g a - f\n",
        "    g <- g\n",
        "    (time is inverted)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_sde, drift_a, T, vtype='rademacher', debias=False):\n",
        "        super().__init__()\n",
        "        self.base_sde = base_sde\n",
        "        self.a = drift_a\n",
        "        self.T = T\n",
        "        self.vtype = vtype\n",
        "        self.debias = debias\n",
        "\n",
        "    # Drift\n",
        "    def mu(self, t, y, lmbd=0.):\n",
        "        return (1. - 0.5 * lmbd) * self.base_sde.g(self.T-t, y) * self.a(y, self.T - t.squeeze()) - \\\n",
        "               self.base_sde.f(self.T - t, y)\n",
        "\n",
        "    # Diffusion\n",
        "    def sigma(self, t, y, lmbd=0.):\n",
        "        return (1. - lmbd) ** 0.5 * self.base_sde.g(self.T-t, y)\n",
        "\n",
        "    @torch.enable_grad()\n",
        "    def dsm(self, x):\n",
        "        \"\"\"\n",
        "        denoising score matching loss\n",
        "        \"\"\"\n",
        "        if self.debias:\n",
        "            t_ = self.base_sde.sample_debiasing_t([x.size(0), ] + [1 for _ in range(x.ndim - 1)])\n",
        "        else:\n",
        "            t_ = torch.rand([x.size(0), ] + [1 for _ in range(x.ndim - 1)]).to(x) * self.T\n",
        "        y, target, std, g = self.base_sde.sample(t_, x, return_noise=True)\n",
        "        a = self.a(y, t_.squeeze())\n",
        "\n",
        "        return ((a * std / g + target) ** 2).view(x.size(0), -1).sum(1, keepdim=False) / 2\n",
        "\n",
        "    @torch.enable_grad()\n",
        "    def elbo_random_t_slice(self, x):\n",
        "        \"\"\"\n",
        "        estimating the ELBO of the plug-in reverse SDE by sampling t uniformly between [0, T], and by estimating\n",
        "        div(mu) using the Hutchinson trace estimator\n",
        "        \"\"\"\n",
        "        t_ = torch.rand([x.size(0), ] + [1 for _ in range(x.ndim - 1)]).to(x) * self.T\n",
        "        qt = 1 / self.T\n",
        "        y = self.base_sde.sample(t_, x).requires_grad_()\n",
        "\n",
        "        a = self.a(y, t_.squeeze())\n",
        "        mu = self.base_sde.g(t_, y) * a - self.base_sde.f(t_, y)\n",
        "\n",
        "        v = sample_v(x.shape, vtype=self.vtype).to(y)\n",
        "\n",
        "        Mu = - (\n",
        "              torch.autograd.grad(mu, y, v, create_graph=self.training)[0] * v\n",
        "        ).view(x.size(0), -1).sum(1, keepdim=False) / qt\n",
        "\n",
        "        Nu = - (a ** 2).view(x.size(0), -1).sum(1, keepdim=False) / 2 / qt\n",
        "        yT = self.base_sde.sample(torch.ones_like(t_) * self.base_sde.T, x)\n",
        "        lp = log_normal(yT, torch.zeros_like(yT), torch.zeros_like(yT)).view(x.size(0), -1).sum(1)\n",
        "\n",
        "        return lp + Mu + Nu\n",
        "\n",
        "    def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
        "        \"\"\"The loss function for training score-based generative models.\n",
        "\n",
        "        Args:\n",
        "            model: A PyTorch model instance that represents a \n",
        "            time-dependent score-based model.\n",
        "            x: A mini-batch of training data.    \n",
        "            marginal_prob_std: A function that gives the standard deviation of \n",
        "            the perturbation kernel.\n",
        "            eps: A tolerance value for numerical stability.\n",
        "        \"\"\"\n",
        "        random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
        "        z = torch.randn_like(x)\n",
        "        std = marginal_prob_std(random_t)\n",
        "        perturbed_x = x + z * std[:, None, None, None]\n",
        "        score = model(perturbed_x, random_t)\n",
        "        loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vMRUGOZvmv0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
